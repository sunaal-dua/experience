{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M1(part2b) - Base Model Approach 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F71q95jI8EiG"
      },
      "source": [
        "**Approach 2 - Long-Short Term Memory (LSTM's)**<br>\r\n",
        "**RUN THIS CELL IF RUNNING IN GOOGLE COLAB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkk7yJOi7W4v",
        "outputId": "37ee1fb8-625b-4dbb-e8e3-5de3e6d160af"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append('/content/drive/MyDrive/Automatic Ticket Assignment')\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2seG6Pb8dhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c731a6-3cca-4021-eea6-45b42acbd976"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\r\n",
        "from ProjectModules.PlottingModule import distribution_plot\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input, GlobalMaxPool1D\r\n",
        "from Model.DLModelTuningAndEvaluation import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "installing wordcloud python package...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFWAGONSfSd4"
      },
      "source": [
        "**Loading upsampled data from part2a:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "jf_92zCc8s6M",
        "outputId": "b1a922a0-14e1-49d8-9893-e1e75b59ea74"
      },
      "source": [
        "# RUN THIS DATAPATH IF RUNNING IN GOOGLE COLAB, GIVE THE CORRECT PATH TO THE DATA\r\n",
        "DATAPATH = '/content/drive/MyDrive/Automatic Ticket Assignment/DataFiles/'\r\n",
        "# *************************** --------------------------************************************\r\n",
        "# DATAPATH = 'DataFiles/'\r\n",
        "\r\n",
        "data = pd.read_csv(DATAPATH+\"upsampled_processed_data.csv\")\r\n",
        "df = data.copy() #making copy of the data\r\n",
        "print(df.shape)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8040, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_short_desc</th>\n",
              "      <th>cleaned_desc</th>\n",
              "      <th>combined_tokens</th>\n",
              "      <th>Assignment group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verify user detail employee manager name check...</td>\n",
              "      <td>login issue verify user detail employee manage...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>team meeting skype meeting etc appear outlook ...</td>\n",
              "      <td>outlook team meeting skype meeting etc appear ...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>cannot log vpn best</td>\n",
              "      <td>cant log vpn cannot log vpn best</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page unable access hr to...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error skype error</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           cleaned_short_desc  ... Assignment group\n",
              "0                 login issue  ...            GRP_0\n",
              "1                     outlook  ...            GRP_0\n",
              "2                cant log vpn  ...            GRP_0\n",
              "3  unable access hr tool page  ...            GRP_0\n",
              "4                 skype error  ...            GRP_0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clPWyuUdfadU"
      },
      "source": [
        "**we will drop the combined_tokens column and will create a new combined_tokens column again in a slightly different way. Earlier we simply merged the short description and description column since we had to make bow and tfidf matrix but now since we will be making using of \"sequences\" we cant have repetitive sequences one after another. We have a lot of records where short description and description are exactly same... hence if they are exactly same we dont want to club them and unnecessarily increase the length of our sequences therefore we will club them in a better way later on:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGtQUo0qLScK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "2caf11a9-0bb1-4477-de5a-75e9c46a21ec"
      },
      "source": [
        "df.drop(\"combined_tokens\", inplace=True, axis=1)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_short_desc</th>\n",
              "      <th>cleaned_desc</th>\n",
              "      <th>Assignment group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verify user detail employee manager name check...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>team meeting skype meeting etc appear outlook ...</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>cannot log vpn best</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           cleaned_short_desc  ... Assignment group\n",
              "0                 login issue  ...            GRP_0\n",
              "1                     outlook  ...            GRP_0\n",
              "2                cant log vpn  ...            GRP_0\n",
              "3  unable access hr tool page  ...            GRP_0\n",
              "4                 skype error  ...            GRP_0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a38VpElVB_HU"
      },
      "source": [
        "**As we explained in part2a before, we removed only those records that had missing values in both description and short description columns. If either of the two had text, we retained it<br>\r\n",
        "The missing text was saved with an empty string in the dataframe during pre-processing, but when we converted it to csv and loaded it again, the empty strings display with NaN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fSvbSQA84zT",
        "outputId": "870a7b05-bd58-4acd-9916-bc319cf3d12d"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cleaned_short_desc    16\n",
              "cleaned_desc          52\n",
              "Assignment group       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-A-VK8LCWta"
      },
      "source": [
        "Otherwise if you'll see there is no record where both description and short description are missing: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "kusxMCz187-P",
        "outputId": "b56168fc-a578-4fc2-a4ca-2647b966e6a6"
      },
      "source": [
        "df[(df['cleaned_short_desc'].isnull()) & (df['cleaned_desc'].isnull())]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_short_desc</th>\n",
              "      <th>cleaned_desc</th>\n",
              "      <th>Assignment group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [cleaned_short_desc, cleaned_desc, Assignment group]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpMdOGWNCen-"
      },
      "source": [
        "So lets fill NaNs with empty string again:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo3IWS-C8-ab"
      },
      "source": [
        "df['cleaned_short_desc'].fillna(value=\"\",inplace=True)\r\n",
        "df['cleaned_desc'].fillna(value = \"\",inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAprR18oCcQQ"
      },
      "source": [
        "**Making vocabulary:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BHtnOm_ClQo",
        "outputId": "04eb052c-7ab0-4de9-8a76-f1f5e11c24e7"
      },
      "source": [
        "vocabulary = set()\r\n",
        "\r\n",
        "for txt in df[\"cleaned_desc\"]:\r\n",
        "    unq_words = set(txt.split())\r\n",
        "    vocabulary.update(unq_words)\r\n",
        "\r\n",
        "for txt in df[\"cleaned_short_desc\"]:\r\n",
        "    unq_words = set(txt.split())\r\n",
        "    vocabulary.update(unq_words)\r\n",
        "\r\n",
        "# appending 'DUMMYWORD' which will be helpful in padding\r\n",
        "vocabulary = list(vocabulary)\r\n",
        "vocabulary.append(\"DUMMYWORD\")\r\n",
        "\r\n",
        "print(\"Total unique words in the vocabulary from both description and short description:\",len(vocabulary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique words in the vocabulary from both description and short description: 19235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBzmDa-MggC0"
      },
      "source": [
        "**Converting vocabulary to numerical values:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xYIMfEPClfk"
      },
      "source": [
        "# mapping vocabulary to numbers\r\n",
        "vocab2id = {w: i for i, w in enumerate(vocabulary)}\r\n",
        "\r\n",
        "# mapping numbers to vocabulary\r\n",
        "id2vocab = {v: k for k, v in vocab2id.items()}\r\n",
        "\r\n",
        "# transforming dataset to numerical tokens\r\n",
        "def convert_words_to_numbers(txt):\r\n",
        "  return [vocab2id[i] for i in txt.split()]\r\n",
        "\r\n",
        "# transforming\r\n",
        "df[\"desc_transformed\"] = df[\"cleaned_desc\"].apply(convert_words_to_numbers)\r\n",
        "df[\"shortdesc_transformed\"] = df[\"cleaned_short_desc\"].apply(convert_words_to_numbers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_UD3QvSgsCb"
      },
      "source": [
        "**desc_transformed and shortdesc_transformed are the numerical versions of cleaned_short_desc and cleaned_desc columns**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "kSQiOsMVCliC",
        "outputId": "ea013a54-5334-4985-a328-ba36c8c41bab"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_short_desc</th>\n",
              "      <th>cleaned_desc</th>\n",
              "      <th>Assignment group</th>\n",
              "      <th>desc_transformed</th>\n",
              "      <th>shortdesc_transformed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verify user detail employee manager name check...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[4924, 12794, 8380, 3682, 4240, 8374, 2112, 12...</td>\n",
              "      <td>[3284, 328]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>team meeting skype meeting etc appear outlook ...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[4468, 5887, 12614, 5887, 4959, 15325, 7091, 4...</td>\n",
              "      <td>[7091]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>cannot log vpn best</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[13682, 11359, 18032, 16957]</td>\n",
              "      <td>[10937, 11359, 18032]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[2374, 6200, 18132, 14462, 6902]</td>\n",
              "      <td>[2374, 6200, 18132, 14462, 6902]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[12614, 2286]</td>\n",
              "      <td>[12614, 2286]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           cleaned_short_desc  ...             shortdesc_transformed\n",
              "0                 login issue  ...                       [3284, 328]\n",
              "1                     outlook  ...                            [7091]\n",
              "2                cant log vpn  ...             [10937, 11359, 18032]\n",
              "3  unable access hr tool page  ...  [2374, 6200, 18132, 14462, 6902]\n",
              "4                 skype error  ...                     [12614, 2286]\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "432II2aug3vl"
      },
      "source": [
        "**Combining tokens - like we said we have descriptions and short descriptions that are exactly same. Hence below is a function that returns only description tokens if both are exactly same and if not... it returns description and short description tokens after clubbing them together**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Q3lcrhIuda"
      },
      "source": [
        "def clubbing_columns(row):\r\n",
        "  if(row[\"shortdesc_transformed\"] == row[\"desc_transformed\"]):\r\n",
        "    return row[\"desc_transformed\"]\r\n",
        "  else:\r\n",
        "    return row[\"shortdesc_transformed\"] + row[\"desc_transformed\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLCFJbYyIYaI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8b127222-fc9f-4739-eff8-05a62ada4a59"
      },
      "source": [
        "df[\"combined_tokens\"] = df[[\"shortdesc_transformed\",\"desc_transformed\"]].apply(clubbing_columns, axis=1)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_short_desc</th>\n",
              "      <th>cleaned_desc</th>\n",
              "      <th>Assignment group</th>\n",
              "      <th>desc_transformed</th>\n",
              "      <th>shortdesc_transformed</th>\n",
              "      <th>combined_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verify user detail employee manager name check...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[4924, 12794, 8380, 3682, 4240, 8374, 2112, 12...</td>\n",
              "      <td>[3284, 328]</td>\n",
              "      <td>[3284, 328, 4924, 12794, 8380, 3682, 4240, 837...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>team meeting skype meeting etc appear outlook ...</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[4468, 5887, 12614, 5887, 4959, 15325, 7091, 4...</td>\n",
              "      <td>[7091]</td>\n",
              "      <td>[7091, 4468, 5887, 12614, 5887, 4959, 15325, 7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>cannot log vpn best</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[13682, 11359, 18032, 16957]</td>\n",
              "      <td>[10937, 11359, 18032]</td>\n",
              "      <td>[10937, 11359, 18032, 13682, 11359, 18032, 16957]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[2374, 6200, 18132, 14462, 6902]</td>\n",
              "      <td>[2374, 6200, 18132, 14462, 6902]</td>\n",
              "      <td>[2374, 6200, 18132, 14462, 6902]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>[12614, 2286]</td>\n",
              "      <td>[12614, 2286]</td>\n",
              "      <td>[12614, 2286]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           cleaned_short_desc  ...                                    combined_tokens\n",
              "0                 login issue  ...  [3284, 328, 4924, 12794, 8380, 3682, 4240, 837...\n",
              "1                     outlook  ...  [7091, 4468, 5887, 12614, 5887, 4959, 15325, 7...\n",
              "2                cant log vpn  ...  [10937, 11359, 18032, 13682, 11359, 18032, 16957]\n",
              "3  unable access hr tool page  ...                   [2374, 6200, 18132, 14462, 6902]\n",
              "4                 skype error  ...                                      [12614, 2286]\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q27n5OTMh2kT"
      },
      "source": [
        "**Checking for Null values again:**<br>No missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YX7mn1NLKc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab37d461-bef3-40f4-df1f-7b537399f5f5"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cleaned_short_desc       0\n",
              "cleaned_desc             0\n",
              "Assignment group         0\n",
              "desc_transformed         0\n",
              "shortdesc_transformed    0\n",
              "combined_tokens          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY6wa98Zh_QD"
      },
      "source": [
        "**Lets transform the target variable. We have 74 unique labels in the target class. We will transform the target variable in the one-hot binarizer form:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "pjwZ1pJNKlJZ",
        "outputId": "74b9949f-94fa-4e19-a840-c39ff88ed5b1"
      },
      "source": [
        "df=pd.get_dummies(df, columns=['Assignment group'])\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_short_desc</th>\n",
              "      <th>cleaned_desc</th>\n",
              "      <th>desc_transformed</th>\n",
              "      <th>shortdesc_transformed</th>\n",
              "      <th>combined_tokens</th>\n",
              "      <th>Assignment group_GRP_0</th>\n",
              "      <th>Assignment group_GRP_1</th>\n",
              "      <th>Assignment group_GRP_10</th>\n",
              "      <th>Assignment group_GRP_11</th>\n",
              "      <th>Assignment group_GRP_12</th>\n",
              "      <th>Assignment group_GRP_13</th>\n",
              "      <th>Assignment group_GRP_14</th>\n",
              "      <th>Assignment group_GRP_15</th>\n",
              "      <th>Assignment group_GRP_16</th>\n",
              "      <th>Assignment group_GRP_17</th>\n",
              "      <th>Assignment group_GRP_18</th>\n",
              "      <th>Assignment group_GRP_19</th>\n",
              "      <th>Assignment group_GRP_2</th>\n",
              "      <th>Assignment group_GRP_20</th>\n",
              "      <th>Assignment group_GRP_21</th>\n",
              "      <th>Assignment group_GRP_22</th>\n",
              "      <th>Assignment group_GRP_23</th>\n",
              "      <th>Assignment group_GRP_24</th>\n",
              "      <th>Assignment group_GRP_25</th>\n",
              "      <th>Assignment group_GRP_26</th>\n",
              "      <th>Assignment group_GRP_27</th>\n",
              "      <th>Assignment group_GRP_28</th>\n",
              "      <th>Assignment group_GRP_29</th>\n",
              "      <th>Assignment group_GRP_3</th>\n",
              "      <th>Assignment group_GRP_30</th>\n",
              "      <th>Assignment group_GRP_31</th>\n",
              "      <th>Assignment group_GRP_32</th>\n",
              "      <th>Assignment group_GRP_33</th>\n",
              "      <th>Assignment group_GRP_34</th>\n",
              "      <th>Assignment group_GRP_35</th>\n",
              "      <th>Assignment group_GRP_36</th>\n",
              "      <th>Assignment group_GRP_37</th>\n",
              "      <th>Assignment group_GRP_38</th>\n",
              "      <th>Assignment group_GRP_39</th>\n",
              "      <th>Assignment group_GRP_4</th>\n",
              "      <th>Assignment group_GRP_40</th>\n",
              "      <th>Assignment group_GRP_41</th>\n",
              "      <th>Assignment group_GRP_42</th>\n",
              "      <th>Assignment group_GRP_43</th>\n",
              "      <th>Assignment group_GRP_44</th>\n",
              "      <th>Assignment group_GRP_45</th>\n",
              "      <th>Assignment group_GRP_46</th>\n",
              "      <th>Assignment group_GRP_47</th>\n",
              "      <th>Assignment group_GRP_48</th>\n",
              "      <th>Assignment group_GRP_49</th>\n",
              "      <th>Assignment group_GRP_5</th>\n",
              "      <th>Assignment group_GRP_50</th>\n",
              "      <th>Assignment group_GRP_51</th>\n",
              "      <th>Assignment group_GRP_52</th>\n",
              "      <th>Assignment group_GRP_53</th>\n",
              "      <th>Assignment group_GRP_54</th>\n",
              "      <th>Assignment group_GRP_55</th>\n",
              "      <th>Assignment group_GRP_56</th>\n",
              "      <th>Assignment group_GRP_57</th>\n",
              "      <th>Assignment group_GRP_58</th>\n",
              "      <th>Assignment group_GRP_59</th>\n",
              "      <th>Assignment group_GRP_6</th>\n",
              "      <th>Assignment group_GRP_60</th>\n",
              "      <th>Assignment group_GRP_61</th>\n",
              "      <th>Assignment group_GRP_62</th>\n",
              "      <th>Assignment group_GRP_63</th>\n",
              "      <th>Assignment group_GRP_64</th>\n",
              "      <th>Assignment group_GRP_65</th>\n",
              "      <th>Assignment group_GRP_66</th>\n",
              "      <th>Assignment group_GRP_67</th>\n",
              "      <th>Assignment group_GRP_68</th>\n",
              "      <th>Assignment group_GRP_69</th>\n",
              "      <th>Assignment group_GRP_7</th>\n",
              "      <th>Assignment group_GRP_70</th>\n",
              "      <th>Assignment group_GRP_71</th>\n",
              "      <th>Assignment group_GRP_72</th>\n",
              "      <th>Assignment group_GRP_73</th>\n",
              "      <th>Assignment group_GRP_8</th>\n",
              "      <th>Assignment group_GRP_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verify user detail employee manager name check...</td>\n",
              "      <td>[4924, 12794, 8380, 3682, 4240, 8374, 2112, 12...</td>\n",
              "      <td>[3284, 328]</td>\n",
              "      <td>[3284, 328, 4924, 12794, 8380, 3682, 4240, 837...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>team meeting skype meeting etc appear outlook ...</td>\n",
              "      <td>[4468, 5887, 12614, 5887, 4959, 15325, 7091, 4...</td>\n",
              "      <td>[7091]</td>\n",
              "      <td>[7091, 4468, 5887, 12614, 5887, 4959, 15325, 7...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log vpn</td>\n",
              "      <td>cannot log vpn best</td>\n",
              "      <td>[13682, 11359, 18032, 16957]</td>\n",
              "      <td>[10937, 11359, 18032]</td>\n",
              "      <td>[10937, 11359, 18032, 13682, 11359, 18032, 16957]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>unable access hr tool page</td>\n",
              "      <td>[2374, 6200, 18132, 14462, 6902]</td>\n",
              "      <td>[2374, 6200, 18132, 14462, 6902]</td>\n",
              "      <td>[2374, 6200, 18132, 14462, 6902]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>[12614, 2286]</td>\n",
              "      <td>[12614, 2286]</td>\n",
              "      <td>[12614, 2286]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           cleaned_short_desc  ... Assignment group_GRP_9\n",
              "0                 login issue  ...                      0\n",
              "1                     outlook  ...                      0\n",
              "2                cant log vpn  ...                      0\n",
              "3  unable access hr tool page  ...                      0\n",
              "4                 skype error  ...                      0\n",
              "\n",
              "[5 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmgntD2xiTzE"
      },
      "source": [
        "**Seperating features and target:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnNULDTuNwa-",
        "outputId": "d8430590-bb50-44f8-9ca2-b647a641a657"
      },
      "source": [
        "ynames = list(df.iloc[:,5:].columns)\r\n",
        "y = df.iloc[:,5:].values\r\n",
        "x = df[\"combined_tokens\"]\r\n",
        "\r\n",
        "print('y (target) in a one-hot binarizer form:',y.shape)\r\n",
        "print('features:',x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y (target) in a one-hot binarizer form: (8040, 74)\n",
            "features: (8040,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qnps1gjivQi"
      },
      "source": [
        "For every record we have 1 at the group it belongs to otherwise 0\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DJmcAYrVOPV",
        "outputId": "7ab0f1ad-2951-407c-8410-d8e31e7fc8a8"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i95etcCV8BW"
      },
      "source": [
        "**Should we use binary_crossentropy or categorical_crossentropy?**<br>\r\n",
        "If we have multi-label classification(when a datapoint belongs to multiple classes) we would use binary_crossentropy, but if we have a multi-class classification(when a datapoint belongs to a single classe) we would use a categorical_crossentropy.<br><br>\r\n",
        "So for every record we have 1 at the group it belongs to... so if we sum across axis=1 and find the max, it should be 1; which means that we have all 0's except one 1(hot) at the group(class) that particular record belongs to. In other words each datapoint just belongs to 1 class. Hence this is a multi-class classification and thus we will use categorical_crossentropy\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIxffexCPxYP",
        "outputId": "b0882f6c-f520-45c6-9ee0-2d7c2e243f8a"
      },
      "source": [
        "np.sum(y,axis=1).max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Y09tPfXbu7"
      },
      "source": [
        "**Transforming combined_tokens into sequences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hshOt3oyM4hX"
      },
      "source": [
        "x_seq = [seq for seq in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "G2XBAfSVM4j5",
        "outputId": "5afcf0da-9b3d-401d-aa23-d5ddacbdea9c"
      },
      "source": [
        "size_of_sequences = [len(i) for i in x]\r\n",
        "\r\n",
        "percentile90 = round(np.percentile(a=size_of_sequences, q=90),2)\r\n",
        "percentile95 = round(np.percentile(a=size_of_sequences, q=95),2)\r\n",
        "mean_size = round(np.mean(size_of_sequences),2) \r\n",
        "max_size = round(np.max(size_of_sequences),2)\r\n",
        "\r\n",
        "print(\" Max no. of tokens in short description (sequence): \",max_size)\r\n",
        "print(\" Avg. no. of tokens in short description (sequence): \",mean_size)\r\n",
        "print(\" 90% of the sequences are <=\",percentile90)\r\n",
        "print(\" 95% of the sequences are <=\",percentile95)\r\n",
        "distribution_plot(size_of_sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Max no. of tokens in short description (sequence):  1820\n",
            " Avg. no. of tokens in short description (sequence):  25.32\n",
            " 90% of the sequences are <= 46.0\n",
            " 95% of the sequences are <= 76.05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm0BFMCTXjfv"
      },
      "source": [
        "**95% of the sequence is 76.05 or below 76.05 whilst 90% of the sequences are 46 and below 46. Hence we will pad the sequence to 76**<br>\r\n",
        "**This means that sequnces greater than 76 will be trimmed down to 76 and sequences less than 76 will be padded to 76, thereby making all the sequences of the same size**<br>\r\n",
        "**Since 95% of the sequences in the dataset is <=76, hence it seems to be the apt value for padding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o8ZTYlUb-sh",
        "outputId": "58575775-5d3f-4311-be09-0000804f4573"
      },
      "source": [
        "len(vocabulary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeEhnyFcYF_5"
      },
      "source": [
        "**Size of the vocabulary is 19235 i.e words are numbered from 0 - 19234**<br>\r\n",
        "Like we said that the sequences that are less than 76 will be padded to be 76, therefore the padding will be done with the number '19234' i.e all padded words will be 19234 and 19234 encodes the word 'DUMMYWORD'. Hence the padding word will be 'DUMMYWORD'<br><br>\r\n",
        "**Also we will do pre-padding.** This is because LSTMs are temporal i.e it has timestamps. Hence words coming at the later timestamps are retained more in the 'memory' as compared to the words at the beginning of the sequence. Hence we want dummy words in the beginning of the sequence instead at the end\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K5kPwJ8tJ4nE",
        "outputId": "599cb436-8c83-4f16-c9bd-c5321c35a15f"
      },
      "source": [
        "# 19234 encodes 'DUMMYWORD'\r\n",
        "id2vocab[19234]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DUMMYWORD'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfU9BhLAa87P"
      },
      "source": [
        "Pre-Padding with value len(vocabulary)-1 i.e 19234 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4QbPzikblPh",
        "outputId": "3572d164-80fd-4ed3-dd9c-64ed918b8245"
      },
      "source": [
        "x_pad = pad_sequences(maxlen=76, sequences=x_seq, padding=\"pre\", value=len(vocabulary)-1)\r\n",
        "\r\n",
        "print(\"shape of x before padding\",np.array(x_seq).shape)\r\n",
        "print(\"shape of x after padding\",x_pad.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of x before padding (8040,)\n",
            "shape of x after padding (8040, 76)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd79VYsobM64"
      },
      "source": [
        "**Now we can make a 80:20 train test split:**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-pu9F6UiCWB",
        "outputId": "e5902a86-40c2-4bf8-efc4-b75e50bf0e17"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_pad, y, test_size=0.20, random_state=777, stratify=y)\r\n",
        "\r\n",
        "print(\"train set\",x_train.shape)\r\n",
        "print(\"train labels\",y_train.shape,\"\\n\\n\")\r\n",
        "print(\"test set\",x_test.shape)\r\n",
        "print(\"test labels\",y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set (6432, 76)\n",
            "train labels (6432, 74) \n",
            "\n",
            "\n",
            "test set (1608, 76)\n",
            "test labels (1608, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaOV_4YtbSoi"
      },
      "source": [
        "**Creating glove embedding for the vocabulary:**<br>\r\n",
        "We will try both **pre-trained glove embeddings** and **tensorflow's default embedding training** that tensorflow trains during the training process<br><br>GloVe 200d download link: https://www.kaggle.com/incorpes/glove6b200d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcpOZtIUNCz4"
      },
      "source": [
        "EMBEDDING_FILE = 'glove.6B.200d.txt'\r\n",
        "\r\n",
        "embeddings = {}\r\n",
        "for o in open(\"/content/drive/My Drive/Automatic Ticket Assignment/\"+EMBEDDING_FILE):\r\n",
        "    word = o.split(\" \")[0]\r\n",
        "    embd = o.split(\" \")[1:]\r\n",
        "    embd = np.asarray(embd, dtype='float32')\r\n",
        "    embeddings[word] = embd\r\n",
        "\r\n",
        "# create a weight matrix for words in vocabulary\r\n",
        "embedding_matrix = np.zeros((len(vocabulary), 200))\r\n",
        "\r\n",
        "for word, i in vocab2id.items():\r\n",
        "\tembedding_vector = embeddings.get(word)\r\n",
        "\tif embedding_vector is not None:\r\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObuTCzPTcRUT"
      },
      "source": [
        "**All 19235 words have been transformed to corresponding 200 long glove vectors:**<br> We can now use it as the weights in the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QRHQh9Ud8Oo",
        "outputId": "2724acc1-c17f-4638-edc0-f1ec03e6fd60"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19235, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oaak8mi6GAFc"
      },
      "source": [
        "We have imported **Model.DLModelTuningAndEvaluation module**. You can find the DLModelTuningAndEvaluation.py under Model folder.<br>\r\n",
        "You will find 3 functions:<br> \r\n",
        "- **train_model()** to train the model for different purposes like test training, hyper-parameter tuning, longer training with callbacks etc.\r\n",
        "<br> \r\n",
        "- **show_training()** to show and plot the training process<br>\r\n",
        "- **DL_evaluation_metrics()** to evaluate the model on the metrics that we have been using i.e macro F1-Score, macro ROC-AUC and Accuracy\r\n",
        "\r\n",
        "\r\n",
        "<br>**For more information on the functions please refer to the docstrings below:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Uw2Oixsdo1l",
        "outputId": "c5c3561e-a3ec-4a49-883a-ad7387698241"
      },
      "source": [
        "print(train_model.__doc__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  Trains models in different ways. You can use this for tuning the deep learning model as well as simple\n",
            "  training. You can turn on/off callbacks and verbose as per your requirement.\n",
            "\n",
            "  model: pass your model instance\n",
            "\n",
            "  xtr: train set\n",
            "  \n",
            "  ytr: train labels\n",
            "  \n",
            "  xte: test set\n",
            "  \n",
            "  yte: test labels\n",
            "  \n",
            "  optm: optimizer. Takes string argument. Currently supports Adam (specify 'adam') and RmsProp (specify 'rmsprop')\n",
            "  \n",
            "  bs: batch size (default = 32)\n",
            "  \n",
            "  learn_rate: learning rate for the optimizer (default = 0.001)\n",
            "  \n",
            "  forTuning: when this is true it simply trains the model on the training set and evaluate on both train and test set. \n",
            "  It turns off verbose so you can try different learning rates in a loop. Returns trained model, train set metrics\n",
            "  (accuracy and loss) and test set metrics (accuracy and loss) (Default=False)\n",
            "  \n",
            "  callbacks: when this is true it implements model checkpoint, early stopping and ReduceLRPlateau. If this is true,\n",
            "  the next 3 parameters are compulsory (Default=False)\n",
            "\n",
            "    earlystop_params: early stopping parameters (dictionary)\n",
            "    eg: {'monitor':'val_loss', 'min_delta':0.1, 'patience':20, 'verbose':1, 'mode':'min', 'restore_best_weights':True}\n",
            "\n",
            "    reducelr_params: ReduceLROnPlateau parameters (dictionary)\n",
            "    eg: {'monitor':'val_loss', \"factor\":0.1, 'patience':20, 'verbose':1, 'mode':'min', 'min_delta':0.1, 'min_lr':1e-7}\n",
            "\n",
            "    modelchkpnt_params: ModelCheckpoint parameters (dictionary) \n",
            "    eg: {\"chkpnt_filename\":\"somefilename\", \"monitor\":'val_accuracy', \"verbose\":1, \"save_best_only\":True, \"mode\":'max'}\n",
            "\n",
            "  Returns trained model\n",
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPwjFnVOJMaU",
        "outputId": "d852b3a0-59ec-4d99-9166-5ed07d3a8fad"
      },
      "source": [
        "print(show_training.__doc__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  Saves and Plots training history. Plots Loss Vs Epoch and Accuracy Vs Epoch graph as well as ReduceLrOnPlateau\n",
            "  graph (if applicaple)\n",
            "\n",
            "  history: pass model training distory. If you have previously saved training history, you can pass that or\n",
            "  else pass model.history.history\n",
            "\n",
            "  saveit: if True it saves the training history in CSV format at this path: \n",
            "  My Drive/capstone/Model/model histories\n",
            "\n",
            "  filename: name of the csv file to save the history with\n",
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo2OXFFQqCtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177f4b93-9b24-464b-d874-ecaf2774792f"
      },
      "source": [
        "print(DL_evaluation_metrics.__doc__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  Prints Accuracy, F1-Score and ROC-AUC score using Sklearn. Since we have multiclass classification you will need to specify \n",
            "  multi-class strategy and averaging strategy.\n",
            "  NOTE THAT: \n",
            "  - ROC-AUC only support macro averaging; while f1-score supports both macro and micro\n",
            "  - F1-score does not have multi-class parameter hence it does not take 'ovo' or 'ovr' into account. ROC-AUC supports multiclass\n",
            "  - Accuracy is independent of these two parameters. They are not applicable to accuracy\n",
            "\n",
            "  ytrue: true labels (array/list/series)\n",
            "  ypred_proba: predicted probabilities (array/list/series)\n",
            "  multiclass: multi-class strategy; enter 'ovr' for OneVsRest and 'ovo' for OneVsOne (string)\n",
            "  avg: averaging strategy; accepts 'micro', 'macro' and 'weighted' (string)\n",
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4oMjBDGJvtx"
      },
      "source": [
        "**In base approach we will train simple LSTM model with simple architecture, hence we will only be making use of train_model() and DL_evaluation_metrics() in this part**<br><br>\r\n",
        "**As we said above that we will try a simple architecture of the LSTM model in this base approach and we will train with default tensorflow embedding layer that will be trained from scratch in the training process only as well as the pre-trained GloVe embedding layer but with trainable = True in order to customise the pre-trained embedding for our corpus**<br>\r\n",
        "The model architecture is as follows:<br>\r\n",
        "<br>**model1a -**<br>\r\n",
        "- input layer of size 76 (x_train.shape[1])<br>\r\n",
        "- embedding layer with input_dim = size of the vocabulary, output_dim = 200 and input length = size of input i.e x_train.shape[1]<br>\r\n",
        "- LSTM layer with 100 units and return sequence = False<br>\r\n",
        "- Output dense layer with units = # labels in the target i.e 74 (y_train.shape[1])\r\n",
        "\r\n",
        "<br>**model1b -** <br>\r\n",
        "same as above except embedding layer is initialized with embedding_matrix which is trainable<br><br>\r\n",
        "**** We will train with just 10 epochs and batch_size=16*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGiXNG5A0oOa",
        "outputId": "be6559aa-c06f-4e29-b3b4-1279bf5b8cb4"
      },
      "source": [
        "# model1a architecture\r\n",
        "input = Input(shape=(x_train.shape[1],),batch_size=None)\r\n",
        "model1a = Embedding(input_dim=len(vocabulary), output_dim=200, input_length=x_train.shape[1])(input)\r\n",
        "model1a = LSTM(units=100, return_sequences=False)(model1a)\r\n",
        "out = Dense(y_train.shape[1], activation=\"softmax\")(model1a)\r\n",
        "model1a = Model(input, out)\r\n",
        "model1a.summary()\r\n",
        "print(\"\\n\")\r\n",
        "\r\n",
        "# training model1a \r\n",
        "model1a = train_model(model1a, x_train, y_train, x_test, y_test, ep=10, bs=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 76)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_8 (Embedding)      (None, 76, 200)           3847000   \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 100)               120400    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 74)                7474      \n",
            "=================================================================\n",
            "Total params: 3,974,874\n",
            "Trainable params: 3,974,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Epoch 1/10\n",
            "402/402 [==============================] - 36s 89ms/step - loss: 2.4330 - accuracy: 0.4862 - val_loss: 2.0886 - val_accuracy: 0.5267\n",
            "Epoch 2/10\n",
            "402/402 [==============================] - 34s 84ms/step - loss: 1.8083 - accuracy: 0.5763 - val_loss: 1.8232 - val_accuracy: 0.5690\n",
            "Epoch 3/10\n",
            "402/402 [==============================] - 34s 84ms/step - loss: 1.3607 - accuracy: 0.6640 - val_loss: 1.7298 - val_accuracy: 0.6082\n",
            "Epoch 4/10\n",
            "402/402 [==============================] - 35s 87ms/step - loss: 1.0122 - accuracy: 0.7446 - val_loss: 1.6724 - val_accuracy: 0.6182\n",
            "Epoch 5/10\n",
            "402/402 [==============================] - 35s 87ms/step - loss: 0.7321 - accuracy: 0.8193 - val_loss: 1.6319 - val_accuracy: 0.6194\n",
            "Epoch 6/10\n",
            "402/402 [==============================] - 34s 85ms/step - loss: 0.5266 - accuracy: 0.8753 - val_loss: 1.6969 - val_accuracy: 0.6294\n",
            "Epoch 7/10\n",
            "402/402 [==============================] - 34s 86ms/step - loss: 0.3768 - accuracy: 0.9146 - val_loss: 1.7611 - val_accuracy: 0.6182\n",
            "Epoch 8/10\n",
            "402/402 [==============================] - 34s 84ms/step - loss: 0.2748 - accuracy: 0.9342 - val_loss: 1.7995 - val_accuracy: 0.6200\n",
            "Epoch 9/10\n",
            "402/402 [==============================] - 34s 85ms/step - loss: 0.2045 - accuracy: 0.9527 - val_loss: 1.8625 - val_accuracy: 0.6262\n",
            "Epoch 10/10\n",
            "402/402 [==============================] - 34s 84ms/step - loss: 0.1631 - accuracy: 0.9618 - val_loss: 1.9975 - val_accuracy: 0.6381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiN9ZcTZfMxa",
        "outputId": "f685638b-4393-4dfd-81a4-70f8713b673e"
      },
      "source": [
        "ytr_pred = model1a.predict(x_train)\r\n",
        "yte_pred = model1a.predict(x_test)\r\n",
        "\r\n",
        "print(\"Train set performance:\")\r\n",
        "DL_evaluation_metrics(y_train, ytr_pred, \"ovo\", \"macro\")\r\n",
        "\r\n",
        "print(\"\\nTest set performance:\")\r\n",
        "DL_evaluation_metrics(y_test, yte_pred, \"ovo\", \"macro\")\r\n",
        "\r\n",
        "print(\"\\n**As explained in part2a - micro-metrics will be similar to accuracy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set performance:\n",
            "Accuracy: 0.9704601990049752\n",
            "(macro) ROC-AUC: 0.9993789540709099\n",
            "(macro) F1 Score: 0.942657489434116\n",
            "\n",
            "Test set performance:\n",
            "Accuracy: 0.6380597014925373\n",
            "(macro) ROC-AUC: 0.8938821743964769\n",
            "(macro) F1 Score: 0.46343556869866337\n",
            "\n",
            "**As explained in part2a - micro-metrics will be similar to accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnkaaK50NBcQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TZquy3HevUF",
        "outputId": "ddc05619-8f55-4b80-f1d2-1f7d033a0fe8"
      },
      "source": [
        "# model1b architecture\r\n",
        "input = Input(shape=(x_train.shape[1],),batch_size=None)\r\n",
        "model1b = Embedding(input_dim=len(vocabulary), output_dim=embedding_matrix.shape[1], weights=[embedding_matrix], input_length=x_train.shape[1], trainable=True)(input)\r\n",
        "model1b = LSTM(units=100, return_sequences=False)(model1b)\r\n",
        "out = Dense(y_train.shape[1], activation=\"softmax\")(model1b)\r\n",
        "model1b = Model(input, out)\r\n",
        "model1b.summary()\r\n",
        "print(\"\\n\")\r\n",
        "\r\n",
        "# train model1b\r\n",
        "train_model(model1b, x_train, y_train, x_test, y_test, ep=10, bs=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 76)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_9 (Embedding)      (None, 76, 200)           3847000   \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 100)               120400    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 74)                7474      \n",
            "=================================================================\n",
            "Total params: 3,974,874\n",
            "Trainable params: 3,974,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Epoch 1/10\n",
            "402/402 [==============================] - 35s 86ms/step - loss: 2.2227 - accuracy: 0.5216 - val_loss: 1.8459 - val_accuracy: 0.5672\n",
            "Epoch 2/10\n",
            "402/402 [==============================] - 34s 83ms/step - loss: 1.5710 - accuracy: 0.6155 - val_loss: 1.5466 - val_accuracy: 0.6132\n",
            "Epoch 3/10\n",
            "402/402 [==============================] - 33s 83ms/step - loss: 1.1671 - accuracy: 0.7041 - val_loss: 1.4436 - val_accuracy: 0.6424\n",
            "Epoch 4/10\n",
            "402/402 [==============================] - 34s 84ms/step - loss: 0.8399 - accuracy: 0.7845 - val_loss: 1.3417 - val_accuracy: 0.6654\n",
            "Epoch 5/10\n",
            "402/402 [==============================] - 34s 84ms/step - loss: 0.5847 - accuracy: 0.8539 - val_loss: 1.3689 - val_accuracy: 0.6636\n",
            "Epoch 6/10\n",
            "402/402 [==============================] - 33s 82ms/step - loss: 0.3969 - accuracy: 0.9044 - val_loss: 1.3724 - val_accuracy: 0.6816\n",
            "Epoch 7/10\n",
            "402/402 [==============================] - 33s 82ms/step - loss: 0.2729 - accuracy: 0.9369 - val_loss: 1.4572 - val_accuracy: 0.6822\n",
            "Epoch 8/10\n",
            "402/402 [==============================] - 35s 87ms/step - loss: 0.1942 - accuracy: 0.9530 - val_loss: 1.5081 - val_accuracy: 0.6729\n",
            "Epoch 9/10\n",
            "402/402 [==============================] - 33s 82ms/step - loss: 0.1471 - accuracy: 0.9661 - val_loss: 1.5708 - val_accuracy: 0.6748\n",
            "Epoch 10/10\n",
            "402/402 [==============================] - 33s 82ms/step - loss: 0.1211 - accuracy: 0.9686 - val_loss: 1.6376 - val_accuracy: 0.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f75b2a09198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5nojnYWZ5QV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141a1927-3670-470c-f223-8a981f4921a5"
      },
      "source": [
        "ytr_pred = model1b.predict(x_train)\r\n",
        "yte_pred = model1b.predict(x_test)\r\n",
        "\r\n",
        "print(\"Train set performance:\")\r\n",
        "DL_evaluation_metrics(y_train, ytr_pred, \"ovo\", \"macro\")\r\n",
        "\r\n",
        "print(\"\\nTest set performance:\")\r\n",
        "DL_evaluation_metrics(y_test, yte_pred, \"ovo\", \"macro\")\r\n",
        "\r\n",
        "print(\"\\n**As explained in part2a - micro-metrics will be similar to accuracy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set performance:\n",
            "Accuracy: 0.9777674129353234\n",
            "(macro) ROC-AUC: 0.9998745406616154\n",
            "(macro) F1 Score: 0.9625536675334205\n",
            "\n",
            "Test set performance:\n",
            "Accuracy: 0.6666666666666666\n",
            "(macro) ROC-AUC: 0.9247985445320637\n",
            "(macro) F1 Score: 0.5134412845374878\n",
            "\n",
            "**As explained in part2a - micro-metrics will be similar to accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2RhQfLKkMIh"
      },
      "source": [
        "### These were are base models in approach 2. Comparing both the approaches, clearly LSTMs standout! Even with very basic architecture they give almost similar results as compared to base 1 approaches.<br> Within LSTMs also, pre-trained GloVe embedding seems to outshine the tensorflow's default embedding that is trained from scratch during the training process.<br>\r\n",
        "### We will thus move on to Milestone 2 and improve upon this existing architecture of the lstm model and tune hyper-parameters. We choose the LSTM with pre-trained GloVe embedding as the model of our choice which we will carry on with in Milestone 2<br>\r\n",
        "**But before that lets save the 3 most important files that we will require in milestone 2:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzHIwrS5pnDL"
      },
      "source": [
        "# # USE THIS SAVEPATH IF RUNNING IN GOOGLE COLAB, GIVE THE PATH WHERE YOU WANT TO SAVE\r\n",
        "# SAVEPATH = '/content/drive/MyDrive/Automatic Ticket Assignment/DataFiles/Milestone2/'\r\n",
        "# # *************************** --------------------------************************************\r\n",
        "# # SAVEPATH = 'DataFiles/Milestone2/'\r\n",
        "\r\n",
        "# np.save(SAVEPATH+'GloveEmbeddingMatrix.npy', embedding_matrix)\r\n",
        "# np.save(SAVEPATH+'xtrain.npy', x_train)\r\n",
        "# np.save(SAVEPATH+'ytrain.npy', y_train)\r\n",
        "# np.save(SAVEPATH+'xtest.npy', x_test)\r\n",
        "# np.save(SAVEPATH+'ytest.npy', y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}