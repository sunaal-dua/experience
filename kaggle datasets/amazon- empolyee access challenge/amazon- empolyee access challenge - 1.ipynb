{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best kaggle scores:\n",
    "### 86.6% AUC - part 1, random forest and part 4, gradient boosting\n",
    "### 86.1% AUC - part 3, logistic regression with L1 regularization\n",
    "### 85.4% AUC - part 1, gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt       \n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58921, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv('test.csv')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns=str.lower,inplace=True)\n",
    "test.rename(columns=str.lower,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>resource</th>\n",
       "      <th>mgr_id</th>\n",
       "      <th>role_rollup_1</th>\n",
       "      <th>role_rollup_2</th>\n",
       "      <th>role_deptname</th>\n",
       "      <th>role_title</th>\n",
       "      <th>role_family_desc</th>\n",
       "      <th>role_family</th>\n",
       "      <th>role_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39353</td>\n",
       "      <td>85475</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>123472</td>\n",
       "      <td>117905</td>\n",
       "      <td>117906</td>\n",
       "      <td>290919</td>\n",
       "      <td>117908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17183</td>\n",
       "      <td>1540</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>123125</td>\n",
       "      <td>118536</td>\n",
       "      <td>118536</td>\n",
       "      <td>308574</td>\n",
       "      <td>118539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>36724</td>\n",
       "      <td>14457</td>\n",
       "      <td>118219</td>\n",
       "      <td>118220</td>\n",
       "      <td>117884</td>\n",
       "      <td>117879</td>\n",
       "      <td>267952</td>\n",
       "      <td>19721</td>\n",
       "      <td>117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36135</td>\n",
       "      <td>5396</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>119993</td>\n",
       "      <td>118321</td>\n",
       "      <td>240983</td>\n",
       "      <td>290919</td>\n",
       "      <td>118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>42680</td>\n",
       "      <td>5905</td>\n",
       "      <td>117929</td>\n",
       "      <td>117930</td>\n",
       "      <td>119569</td>\n",
       "      <td>119323</td>\n",
       "      <td>123932</td>\n",
       "      <td>19793</td>\n",
       "      <td>119325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action  resource  mgr_id  role_rollup_1  role_rollup_2  role_deptname  \\\n",
       "0       1     39353   85475         117961         118300         123472   \n",
       "1       1     17183    1540         117961         118343         123125   \n",
       "2       1     36724   14457         118219         118220         117884   \n",
       "3       1     36135    5396         117961         118343         119993   \n",
       "4       1     42680    5905         117929         117930         119569   \n",
       "\n",
       "   role_title  role_family_desc  role_family  role_code  \n",
       "0      117905            117906       290919     117908  \n",
       "1      118536            118536       308574     118539  \n",
       "2      117879            267952        19721     117880  \n",
       "3      118321            240983       290919     118322  \n",
       "4      119323            123932        19793     119325  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>resource</th>\n",
       "      <th>mgr_id</th>\n",
       "      <th>role_rollup_1</th>\n",
       "      <th>role_rollup_2</th>\n",
       "      <th>role_deptname</th>\n",
       "      <th>role_title</th>\n",
       "      <th>role_family_desc</th>\n",
       "      <th>role_family</th>\n",
       "      <th>role_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [action, resource, mgr_id, role_rollup_1, role_rollup_2, role_deptname, role_title, role_family_desc, role_family, role_code]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.duplicated()]\n",
    "#no duplicate rows in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32769 entries, 0 to 32768\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   action            32769 non-null  int64\n",
      " 1   resource          32769 non-null  int64\n",
      " 2   mgr_id            32769 non-null  int64\n",
      " 3   role_rollup_1     32769 non-null  int64\n",
      " 4   role_rollup_2     32769 non-null  int64\n",
      " 5   role_deptname     32769 non-null  int64\n",
      " 6   role_title        32769 non-null  int64\n",
      " 7   role_family_desc  32769 non-null  int64\n",
      " 8   role_family       32769 non-null  int64\n",
      " 9   role_code         32769 non-null  int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "#all integer columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action              0\n",
       "resource            0\n",
       "mgr_id              0\n",
       "role_rollup_1       0\n",
       "role_rollup_2       0\n",
       "role_deptname       0\n",
       "role_title          0\n",
       "role_family_desc    0\n",
       "role_family         0\n",
       "role_code           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()\n",
    "#no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**highly imbalanced dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    30872\n",
      "0     1897\n",
      "Name: action, dtype: int64\n",
      "1    0.94211\n",
      "0    0.05789\n",
      "Name: action, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"action\"].value_counts())\n",
    "print(train[\"action\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we can see all the features are categorical with high cardinality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource has 7518 unique labels\n",
      "mgr_id has 4243 unique labels\n",
      "role_rollup_1 has 128 unique labels\n",
      "role_rollup_2 has 177 unique labels\n",
      "role_deptname has 449 unique labels\n",
      "role_title has 343 unique labels\n",
      "role_family_desc has 2358 unique labels\n",
      "role_family has 67 unique labels\n",
      "role_code has 343 unique labels\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns[1:]:\n",
    "    print(col+\" has \"+str(train[col].nunique())+\" unique labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource has 4971 unique labels\n",
      "mgr_id has 4689 unique labels\n",
      "role_rollup_1 has 126 unique labels\n",
      "role_rollup_2 has 177 unique labels\n",
      "role_deptname has 466 unique labels\n",
      "role_title has 351 unique labels\n",
      "role_family_desc has 2749 unique labels\n",
      "role_family has 68 unique labels\n",
      "role_code has 351 unique labels\n"
     ]
    }
   ],
   "source": [
    "for col in test.columns[1:]:\n",
    "    print(col+\" has \"+str(test[col].nunique())+\" unique labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another thing to notice is that in most of the categorical features we have labels that are present in the testing set but not in the training set. In other words there will be labels (for every feature individually) that we will encounter in test set but not in train set, as a result we will not be able to train for them.<br>Lets see how many such labels are there:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: resource | no. of labels present in test set only: 0\n",
      "feature: mgr_id | no. of labels present in test set only: 670\n",
      "feature: role_rollup_1 | no. of labels present in test set only: 2\n",
      "feature: role_rollup_2 | no. of labels present in test set only: 6\n",
      "feature: role_deptname | no. of labels present in test set only: 27\n",
      "feature: role_title | no. of labels present in test set only: 18\n",
      "feature: role_family_desc | no. of labels present in test set only: 593\n",
      "feature: role_family | no. of labels present in test set only: 1\n",
      "feature: role_code | no. of labels present in test set only: 18\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns[1:]:\n",
    "    train_unique_labels=set(train[col])\n",
    "    test_unique_labels=set(test[col])\n",
    "    print(\"feature: \"+col+\" | no. of labels present in test set only: \"+str(len(test_unique_labels-train_unique_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**except \"resource\" all other features have label bias.**<br><br>\n",
    "\n",
    "# PART 1\n",
    "To combat label bias, all the labels(for each feature individually) that are newly encountered in test set will be made 0 representing \"unknown\".\n",
    "Moreover, we can see the cardinality of the features is very high hence one-hot encoding the features would create a lot of dimensionality. It will expand the feature set to 15,617 features. To combat this we will find the normalized value counts of each feature and replace the label with their respective proportion in that feature. Eg: our training set is of size 32769, if a categorical feature has labels A,B,C, where frequency/count of A=30000, B=2000, C=769, then these value will be replaced by A=30000/32769=0.915, B=2000/32769=0.061 and C=0.023.<br>This methodology seems apt to convert categorical labels to numeric values, however it comes at an expense of information loss. There will be some labels that have same no. of counts, we will end up replacing those labels with the same numeric value. Eg: A=30000, B=1000, C=769, D=1000. In such a case we will end up labelling B and D with same proportion i.e 0.030, as a result, B and D will be treated as same label for that feature causing information loss in that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns[1:]:\n",
    "    train[col+\"_new\"] = train[col]\n",
    "    train[col+\"_new\"].replace(train[col].value_counts(normalize=True).to_dict(),inplace=True)\n",
    "    \n",
    "    test[col+\"_new\"] = test[col]\n",
    "    test[col+\"_new\"].replace(train[col].value_counts(normalize=True).to_dict(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000031    3766\n",
      "0.000061    2788\n",
      "0.000092    2280\n",
      "0.000122    1632\n",
      "0.000153    1240\n",
      "            ... \n",
      "0.001587      52\n",
      "0.001556      51\n",
      "0.001495      49\n",
      "0.001434      47\n",
      "0.001404      46\n",
      "Name: resource_new, Length: 101, dtype: int64\n",
      "0.000122    1460\n",
      "0.000092    1356\n",
      "0.000153    1335\n",
      "0.000183    1260\n",
      "0.000244    1216\n",
      "            ... \n",
      "0.002167      71\n",
      "0.002045      67\n",
      "0.002014      66\n",
      "0.001831      60\n",
      "0.001465      48\n",
      "Name: mgr_id_new, Length: 68, dtype: int64\n",
      "0.653270    21407\n",
      "0.022643      742\n",
      "0.022003      721\n",
      "0.015197      498\n",
      "0.012207      400\n",
      "            ...  \n",
      "0.000031       10\n",
      "0.000275        9\n",
      "0.000244        8\n",
      "0.000061        4\n",
      "0.000092        3\n",
      "Name: role_rollup_1_new, Length: 79, dtype: int64\n",
      "0.135006    4424\n",
      "0.120388    3945\n",
      "0.080594    2641\n",
      "0.077726    2547\n",
      "0.054808    1796\n",
      "            ... \n",
      "0.000397      13\n",
      "0.000122      12\n",
      "0.000092      12\n",
      "0.000336      11\n",
      "0.000061       6\n",
      "Name: role_rollup_2_new, Length: 105, dtype: int64\n",
      "0.034636    1135\n",
      "0.023284     763\n",
      "0.020110     659\n",
      "0.009277     608\n",
      "0.018341     601\n",
      "            ... \n",
      "0.000092      39\n",
      "0.001068      35\n",
      "0.000519      34\n",
      "0.000946      31\n",
      "0.000031      24\n",
      "Name: role_deptname_new, Length: 159, dtype: int64\n",
      "0.141872    4649\n",
      "0.109341    3583\n",
      "0.054075    1772\n",
      "0.038329    1256\n",
      "0.031829    1043\n",
      "            ... \n",
      "0.000977      32\n",
      "0.000946      31\n",
      "0.000183      30\n",
      "0.000885      29\n",
      "0.000671      22\n",
      "Name: role_title_new, Length: 126, dtype: int64\n",
      "0.210443    6896\n",
      "0.037963    1244\n",
      "0.000092     756\n",
      "0.000122     744\n",
      "0.000061     742\n",
      "            ... \n",
      "0.001587      52\n",
      "0.001526      50\n",
      "0.001434      47\n",
      "0.001312      43\n",
      "0.001129      37\n",
      "Name: role_family_desc_new, Length: 108, dtype: int64\n",
      "0.335073    10980\n",
      "0.082090     2690\n",
      "0.080442     2636\n",
      "0.073240     2400\n",
      "0.023895     1566\n",
      "0.040221     1318\n",
      "0.039489     1294\n",
      "0.039275     1287\n",
      "0.028716      941\n",
      "0.027221      892\n",
      "0.021026      689\n",
      "0.015045      493\n",
      "0.014190      465\n",
      "0.013702      449\n",
      "0.012573      412\n",
      "0.011718      384\n",
      "0.011047      362\n",
      "0.004577      300\n",
      "0.008972      294\n",
      "0.008941      293\n",
      "0.007355      241\n",
      "0.006836      224\n",
      "0.005798      190\n",
      "0.005524      181\n",
      "0.005371      176\n",
      "0.004883      160\n",
      "0.004455      146\n",
      "0.003906      128\n",
      "0.003509      115\n",
      "0.003387      111\n",
      "0.003296      108\n",
      "0.003265      107\n",
      "0.002991       98\n",
      "0.002502       82\n",
      "0.002380       78\n",
      "0.001770       58\n",
      "0.001617       53\n",
      "0.001495       49\n",
      "0.000610       40\n",
      "0.001190       39\n",
      "0.001068       35\n",
      "0.000915       30\n",
      "0.000824       27\n",
      "0.000702       23\n",
      "0.000214       21\n",
      "0.000580       19\n",
      "0.000488       16\n",
      "0.000458       15\n",
      "0.000092       15\n",
      "0.000153       10\n",
      "0.000275        9\n",
      "0.000122        8\n",
      "0.000061        6\n",
      "0.000183        6\n",
      "Name: role_family_new, dtype: int64\n",
      "0.141872    4649\n",
      "0.109341    3583\n",
      "0.054075    1772\n",
      "0.038329    1256\n",
      "0.031829    1043\n",
      "            ... \n",
      "0.000977      32\n",
      "0.000946      31\n",
      "0.000183      30\n",
      "0.000885      29\n",
      "0.000671      22\n",
      "Name: role_code_new, Length: 126, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns[10:]:\n",
    "    print(train[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As mentioned above we will replace all the newly encountered values in test set to 0 representing \"unknown\". We have encoded the features as explained above as a result all the values are between 0 and 1. Therefore, in the test set, any label greater than 1 will be the label that was not found in the training set and hence was not converted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test.columns[10:]:\n",
    "    test[col][test[col]>1] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource has 7518 unique labels\n",
      "mgr_id has 4243 unique labels\n",
      "role_rollup_1 has 128 unique labels\n",
      "role_rollup_2 has 177 unique labels\n",
      "role_deptname has 449 unique labels\n",
      "role_title has 343 unique labels\n",
      "role_family_desc has 2358 unique labels\n",
      "role_family has 67 unique labels\n",
      "role_code has 343 unique labels\n",
      "resource_new has 101 unique labels\n",
      "mgr_id_new has 68 unique labels\n",
      "role_rollup_1_new has 79 unique labels\n",
      "role_rollup_2_new has 105 unique labels\n",
      "role_deptname_new has 159 unique labels\n",
      "role_title_new has 126 unique labels\n",
      "role_family_desc_new has 108 unique labels\n",
      "role_family_new has 54 unique labels\n",
      "role_code_new has 126 unique labels\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns[1:]:\n",
    "    print(col+\" has \"+str(train[col].nunique())+\" unique labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you compare every feature with its \"new\" alternative you will see that the unique labels are reduced a lot. eg: resource having 7518 unique labels was reduced to 101 unique labels only. This shows that the count of a lot of labels was same as a result we ended up labelling them with the same numeric value, thereby grouping them together. Hence this is a case of information loss but lets see the model performance:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train[train.columns[10:]]\n",
    "y = train[\"action\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100, stratify=y)\n",
    "\n",
    "f_test = test[test.columns[10:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 45, 'class_weight': 'balanced'}\n",
      "\n",
      "auc after 10-fold cv: 0.5988258332657548, SD: 0.037285469265843654\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict(given)</th>\n",
       "      <th>Predict(not given)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Truth(given)</td>\n",
       "      <td>2868</td>\n",
       "      <td>3307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Truth(not given)</td>\n",
       "      <td>122</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predict(given)  Predict(not given)\n",
       "Truth(given)                2868                3307\n",
       "Truth(not given)             122                 257"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(penalty = \"l1\",random_state=7,solver=\"liblinear\")\n",
    "\n",
    "param_dist = {\"C\": sp_randint(1, 1000),\n",
    "              \"class_weight\": [None,\"balanced\"]}\n",
    " \n",
    "randomCV = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20,cv=10,random_state=7,scoring='roc_auc')\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best = randomCV.best_params_\n",
    "print(best)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "cl = LogisticRegression(penalty = \"l1\",C=best[\"C\"],class_weight=best[\"class_weight\"],random_state=7,solver=\"liblinear\")\n",
    "cl_roc = cross_val_score(cl, x_test, y_test, cv=10,scoring=\"roc_auc\")\n",
    "cl_pred = cross_val_predict(cl, x_test, y_test, cv=10)\n",
    "# cl_pred_proba = cross_val_predict(cl, x_test, y_test, cv=10,method='predict_proba')\n",
    "\n",
    "print(\"auc after 10-fold cv: \"+str(cl_roc.mean())+\", SD: \"+str(cl_roc.std()))\n",
    "\n",
    "mat_train = confusion_matrix(y_test,cl_pred,labels=[1,0])\n",
    "cl_cm = pd.DataFrame(mat_train, index = [i for i in [\"Truth(given)\",\"Truth(not given)\"]],\n",
    "                  columns = [i for i in [\"Predict(given)\",\"Predict(not given)\"]])\n",
    "cl_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**randomforest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 90, 'max_features': 5, 'max_depth': 14, 'class_weight': None}\n",
      "\n",
      "auc after 10-fold cv: 0.73448555109605, SD: 0.052003034904018065\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict(given)</th>\n",
       "      <th>Predict(not given)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Truth(given)</td>\n",
       "      <td>6144</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Truth(not given)</td>\n",
       "      <td>350</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predict(given)  Predict(not given)\n",
       "Truth(given)                6144                  31\n",
       "Truth(not given)             350                  29"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=7)\n",
    "\n",
    "param_dist = {\"max_features\": list(np.arange(1,10))+[None,\"sqrt\"],\n",
    "              \"max_depth\":list(np.arange(3,30))+[None],\n",
    "              \"class_weight\":[None,\"balanced\"],\n",
    "              \"n_estimators\": np.arange(10,150,5)}\n",
    " \n",
    "randomCV = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20,cv=10,random_state=7,scoring='roc_auc')\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best = randomCV.best_params_\n",
    "print(best)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "cl = RandomForestClassifier(n_estimators=best[\"n_estimators\"],max_depth=best[\"max_depth\"],max_features=best[\"max_features\"],class_weight=best[\"class_weight\"],random_state=7)\n",
    "\n",
    "cl_roc = cross_val_score(cl, x_test, y_test, cv=10,scoring=\"roc_auc\")\n",
    "cl_pred = cross_val_predict(cl, x_test, y_test, cv=10)\n",
    "\n",
    "print(\"auc after 10-fold cv: \"+str(cl_roc.mean())+\", SD: \"+str(cl_roc.std()))\n",
    "\n",
    "mat_train = confusion_matrix(y_test,cl_pred,labels=[1,0])\n",
    "cl_cm = pd.DataFrame(mat_train, index = [i for i in [\"Truth(given)\",\"Truth(not given)\"]],\n",
    "                  columns = [i for i in [\"Predict(given)\",\"Predict(not given)\"]])\n",
    "cl_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gradient boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 105, 'max_features': 6, 'max_depth': 13}\n",
      "\n",
      "auc after 10-fold cv: 0.7344397212025491, SD: 0.04791514453750168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict(given)</th>\n",
       "      <th>Predict(not given)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Truth(given)</td>\n",
       "      <td>6090</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Truth(not given)</td>\n",
       "      <td>315</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predict(given)  Predict(not given)\n",
       "Truth(given)                6090                  85\n",
       "Truth(not given)             315                  64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(random_state=om_state=7)\n",
    "\n",
    "param_dist = {\"max_features\": list(np.arange(1,10))+[None,\"sqrt\"],\n",
    "              \"max_depth\":list(np.arange(3,30))+[None],\n",
    "              \"n_estimators\": np.arange(10,150,5)}\n",
    " \n",
    "randomCV = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20,cv=10,random_state=7,scoring='roc_auc')\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best = randomCV.best_params_\n",
    "print(best)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "cl = GradientBoostingClassifier(n_estimators=best[\"n_estimators\"],max_depth=best[\"max_depth\"],max_features=best[\"max_features\"],random_state=7)\n",
    "cl_roc = cross_val_score(cl, x_test, y_test, cv=10,scoring=\"roc_auc\")\n",
    "cl_pred = cross_val_predict(cl, x_test, y_test, cv=10)\n",
    "\n",
    "print(\"auc after 10-fold cv: \"+str(cl_roc.mean())+\", SD: \"+str(cl_roc.std()))\n",
    "\n",
    "mat_train = confusion_matrix(y_test,cl_pred,labels=[1,0])\n",
    "cl_cm = pd.DataFrame(mat_train, index = [i for i in [\"Truth(given)\",\"Truth(not given)\"]],\n",
    "                  columns = [i for i in [\"Predict(given)\",\"Predict(not given)\"]])\n",
    "cl_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets see the auc on the kaggle test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 59.2%\n",
    "\n",
    "final_model = LogisticRegression(penalty=\"l1\",C=45,class_weight=\"balanced\",random_state=7,solver=\"liblinear\")\n",
    "final_model.fit(x,y)\n",
    "final_predictions = final_model.predict_proba(f_test)[:, 1]\n",
    "\n",
    "submit = pd.DataFrame(columns=[\"Id\",\"Action\"])\n",
    "submit[\"Action\"] = final_predictions\n",
    "submit[\"Id\"] = test[\"id\"]\n",
    "#submit.to_csv('PT1-lr.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 86.5%\n",
    "\n",
    "final_model = RandomForestClassifier(n_estimators=90, random_state=7, max_features=5, max_depth=14)\n",
    "final_model.fit(x,y)\n",
    "final_predictions = final_model.predict_proba(f_test)[:, 1]\n",
    "\n",
    "submit = pd.DataFrame(columns=[\"Id\",\"Action\"])\n",
    "submit[\"Action\"] = final_predictions\n",
    "submit[\"Id\"] = test[\"id\"]\n",
    "#submit.to_csv('PT1-rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 85.4%\n",
    "\n",
    "final_model = GradientBoostingClassifier(n_estimators=105,max_depth=13,max_features=6,random_state=7)\n",
    "final_model.fit(x,y)\n",
    "final_predictions = final_model.predict_proba(f_test)[:, 1]\n",
    "\n",
    "submit = pd.DataFrame(columns=[\"Id\",\"Action\"])\n",
    "submit[\"Action\"] = final_predictions\n",
    "submit[\"Id\"] = test[\"id\"]\n",
    "#submit.to_csv('PT1-gb.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets see another methodologies for encoding. Before that lets obtain our orignal train and test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.columns[:10]]\n",
    "test = test[test.columns[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2\n",
    "This is another way to encode features having high cardinality, also known as mean target encoding.<br>Here we will groupby the target which is binary (1,0) and find the probability of label being 1. Finally we will replace all the labels with this probability. We will do this for all features. Eg: we have a feature that has the folowing labels: A,B,C and the size of the dataset is 1000. Lets suppose A appears 600 times(out of which 400 times it has target 1 and 200 times 0), B appears 200 times(150 times 1 and 50 times 0) and C appears 200 times(130 times 1 and 70 times 0). A will be replaced by 400/600 = 0.66, B by 150/200 = 0.75 and C by 130/200 = 0.65. In part 1 methodology we se saw that if two labels have same count they will be labelled with the same numeric value resulting in information loss in that feature. However, here we see that even though B and C have same count they have different numeric values because they are grouped by target as a result after grouping the count of label being B and target being 1 is 150 and label being C and target being 1 is 130. Hence the probabilities are different. There can be cases where the total count of the label and count of label being 1 is same which will result in same numeric value for both the labels but likelihood of that happening would be low as compared to part 1 methodology. Lets see if this can improve the model performance:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_enc(col):\n",
    "    df = train[[col,\"action\"]].groupby(by=col).mean()[\"action\"]\n",
    "    train[col+\"--new\"] = train[col].map(df)\n",
    "    test[col+\"--new\"] = test[col].map(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in train.columns[1:]:\n",
    "    mean_enc(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000000    15888\n",
      "0.996424      839\n",
      "0.966942      484\n",
      "0.900000      460\n",
      "0.953545      409\n",
      "            ...  \n",
      "0.545455       11\n",
      "0.250000        8\n",
      "0.125000        8\n",
      "0.166667        6\n",
      "0.200000        5\n",
      "Name: resource--new, Length: 139, dtype: int64\n",
      "1.000000    22011\n",
      "0.750000      328\n",
      "0.666667      306\n",
      "0.937500      288\n",
      "0.857143      287\n",
      "            ...  \n",
      "0.100000       10\n",
      "0.125000        8\n",
      "0.375000        8\n",
      "0.142857        7\n",
      "0.166667        6\n",
      "Name: mgr_id--new, Length: 156, dtype: int64\n",
      "0.949222    21407\n",
      "1.000000      888\n",
      "0.962264      742\n",
      "0.963939      721\n",
      "0.951807      498\n",
      "            ...  \n",
      "0.920000       25\n",
      "0.761905       21\n",
      "0.941176       17\n",
      "0.937500       16\n",
      "0.000000        1\n",
      "Name: role_rollup_1--new, Length: 72, dtype: int64\n",
      "0.956148    4424\n",
      "0.969075    3945\n",
      "0.954563    2641\n",
      "0.957205    2547\n",
      "0.888889    2124\n",
      "            ... \n",
      "0.761905      21\n",
      "0.850000      20\n",
      "0.937500      16\n",
      "0.933333      15\n",
      "0.000000       2\n",
      "Name: role_rollup_2--new, Length: 91, dtype: int64\n",
      "1.000000    3517\n",
      "0.937445    1135\n",
      "0.917431     763\n",
      "0.923077     663\n",
      "0.864947     659\n",
      "            ... \n",
      "0.600000      10\n",
      "0.000000       8\n",
      "0.714286       7\n",
      "0.400000       5\n",
      "0.750000       4\n",
      "Name: role_deptname--new, Length: 201, dtype: int64\n",
      "0.920413    4649\n",
      "0.967625    3583\n",
      "1.000000    2643\n",
      "0.929458    1772\n",
      "0.889331    1256\n",
      "            ... \n",
      "0.916667      12\n",
      "0.909091      11\n",
      "0.625000       8\n",
      "0.428571       7\n",
      "0.000000       4\n",
      "Name: role_title--new, Length: 126, dtype: int64\n",
      "1.000000    10641\n",
      "0.933440     6896\n",
      "0.955788     1244\n",
      "0.968657      670\n",
      "0.924812      665\n",
      "            ...  \n",
      "0.583333       12\n",
      "0.636364       11\n",
      "0.363636       11\n",
      "0.125000        8\n",
      "0.166667        6\n",
      "Name: role_family_desc--new, Length: 138, dtype: int64\n",
      "0.942350    10980\n",
      "0.972491     2690\n",
      "0.907815     2636\n",
      "0.959167     2400\n",
      "0.862671     1318\n",
      "0.952087     1294\n",
      "0.947941     1287\n",
      "0.965994      941\n",
      "0.942825      892\n",
      "0.933589      783\n",
      "0.970626      783\n",
      "0.946299      689\n",
      "0.951318      493\n",
      "0.941935      465\n",
      "0.942094      449\n",
      "0.985437      412\n",
      "0.989796      392\n",
      "0.864583      384\n",
      "0.837017      362\n",
      "0.965870      293\n",
      "1.000000      249\n",
      "0.892116      241\n",
      "0.977679      224\n",
      "0.989474      190\n",
      "0.944751      181\n",
      "0.994318      176\n",
      "0.856250      160\n",
      "0.986667      150\n",
      "0.980000      150\n",
      "0.965753      146\n",
      "0.890625      128\n",
      "0.973913      115\n",
      "0.954955      111\n",
      "0.981481      108\n",
      "0.925234      107\n",
      "0.974359       78\n",
      "0.982759       58\n",
      "0.924528       53\n",
      "0.959184       49\n",
      "0.871795       39\n",
      "0.925926       27\n",
      "0.826087       23\n",
      "0.900000       20\n",
      "0.894737       19\n",
      "0.933333       15\n",
      "0.800000        5\n",
      "0.750000        4\n",
      "Name: role_family--new, dtype: int64\n",
      "0.920413    4649\n",
      "0.967625    3583\n",
      "1.000000    2643\n",
      "0.929458    1772\n",
      "0.889331    1256\n",
      "            ... \n",
      "0.916667      12\n",
      "0.909091      11\n",
      "0.625000       8\n",
      "0.428571       7\n",
      "0.000000       4\n",
      "Name: role_code--new, Length: 126, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns[10:]:\n",
    "    print(train[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we will replace all the newly encountered values in test set by global target mean of the training set. Since the newly encountered values in test set will not be mapped therefore they will be replaced by nan. We will replace all the nan values in the test set by global target mean.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test.columns[10:]:\n",
    "    test[col][test[col].isnull()] = train[\"action\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource has 7518 unique labels\n",
      "mgr_id has 4243 unique labels\n",
      "role_rollup_1 has 128 unique labels\n",
      "role_rollup_2 has 177 unique labels\n",
      "role_deptname has 449 unique labels\n",
      "role_title has 343 unique labels\n",
      "role_family_desc has 2358 unique labels\n",
      "role_family has 67 unique labels\n",
      "role_code has 343 unique labels\n",
      "resource--new has 139 unique labels\n",
      "mgr_id--new has 156 unique labels\n",
      "role_rollup_1--new has 72 unique labels\n",
      "role_rollup_2--new has 91 unique labels\n",
      "role_deptname--new has 201 unique labels\n",
      "role_title--new has 126 unique labels\n",
      "role_family_desc--new has 138 unique labels\n",
      "role_family--new has 47 unique labels\n",
      "role_code--new has 126 unique labels\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns[1:]:\n",
    "    print(col+\" has \"+str(train[col].nunique())+\" unique labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Again the count of a lot of labels was same as a result we ended up labelling them with the same numeric value, thereby grouping them together. Again we see some information loss but here the loss will be less than part 1. lets see the model performance:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train[train.columns[10:]]\n",
    "y = train[\"action\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100, stratify=y)\n",
    "\n",
    "f_test = test[test.columns[10:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 45, 'class_weight': 'balanced'}\n",
      "\n",
      "auc after 10-fold cv: 0.9749136224630212, SD: 0.007805963143871724\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict(given)</th>\n",
       "      <th>Predict(not given)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Truth(given)</td>\n",
       "      <td>5727</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Truth(not given)</td>\n",
       "      <td>45</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predict(given)  Predict(not given)\n",
       "Truth(given)                5727                 448\n",
       "Truth(not given)              45                 334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(penalty = \"l1\",random_state=7,solver=\"liblinear\")\n",
    "\n",
    "param_dist = {\"C\": sp_randint(1, 1000),\n",
    "              \"class_weight\": [None,\"balanced\"]}\n",
    " \n",
    "randomCV = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20,cv=10,random_state=7,scoring='roc_auc')\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best = randomCV.best_params_\n",
    "print(best)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "cl = LogisticRegression(penalty = \"l1\",C=best[\"C\"],class_weight=best[\"class_weight\"],random_state=7,solver=\"liblinear\")\n",
    "cl_roc = cross_val_score(cl, x_test, y_test, cv=10,scoring=\"roc_auc\")\n",
    "cl_pred = cross_val_predict(cl, x_test, y_test, cv=10)\n",
    "\n",
    "print(\"auc after 10-fold cv: \"+str(cl_roc.mean())+\", SD: \"+str(cl_roc.std()))\n",
    "\n",
    "mat_train = confusion_matrix(y_test,cl_pred,labels=[1,0])\n",
    "cl_cm = pd.DataFrame(mat_train, index = [i for i in [\"Truth(given)\",\"Truth(not given)\"]],\n",
    "                  columns = [i for i in [\"Predict(given)\",\"Predict(not given)\"]])\n",
    "cl_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomforest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 45, 'max_features': 5, 'max_depth': 11, 'class_weight': None}\n",
      "\n",
      "auc after 10-fold cv: 0.9825065932157294, SD: 0.00797892676323939\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict(given)</th>\n",
       "      <th>Predict(not given)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Truth(given)</td>\n",
       "      <td>6105</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Truth(not given)</td>\n",
       "      <td>125</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predict(given)  Predict(not given)\n",
       "Truth(given)                6105                  70\n",
       "Truth(not given)             125                 254"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=7)\n",
    "\n",
    "param_dist = {\"max_features\": list(np.arange(1,10))+[None,\"sqrt\"],\n",
    "              \"max_depth\":list(np.arange(3,30))+[None],\n",
    "              \"class_weight\":[None,\"balanced\"],\n",
    "              \"n_estimators\": np.arange(10,150,5)}\n",
    " \n",
    "randomCV = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20,cv=10,random_state=7,scoring='roc_auc')\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best = randomCV.best_params_\n",
    "print(best)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "cl = RandomForestClassifier(n_estimators=best[\"n_estimators\"],max_depth=best[\"max_depth\"],max_features=best[\"max_features\"],class_weight=best[\"class_weight\"],random_state=7)\n",
    "\n",
    "cl_roc = cross_val_score(cl, x_test, y_test, cv=10,scoring=\"roc_auc\")\n",
    "cl_pred = cross_val_predict(cl, x_test, y_test, cv=10)\n",
    "\n",
    "print(\"auc after 10-fold cv: \"+str(cl_roc.mean())+\", SD: \"+str(cl_roc.std()))\n",
    "\n",
    "mat_train = confusion_matrix(y_test,cl_pred,labels=[1,0])\n",
    "cl_cm = pd.DataFrame(mat_train, index = [i for i in [\"Truth(given)\",\"Truth(not given)\"]],\n",
    "                  columns = [i for i in [\"Predict(given)\",\"Predict(not given)\"]])\n",
    "cl_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 125, 'max_features': 'sqrt', 'max_depth': 5}\n",
      "\n",
      "auc after 10-fold cv: 0.98632094850416, SD: 0.004090922485176993\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict(given)</th>\n",
       "      <th>Predict(not given)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Truth(given)</td>\n",
       "      <td>6103</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Truth(not given)</td>\n",
       "      <td>122</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predict(given)  Predict(not given)\n",
       "Truth(given)                6103                  72\n",
       "Truth(not given)             122                 257"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(random_state=7)\n",
    "\n",
    "param_dist = {\"max_features\": list(np.arange(1,10))+[None,\"sqrt\"],\n",
    "              \"max_depth\":list(np.arange(3,30))+[None],\n",
    "              \"n_estimators\": np.arange(10,150,5)}\n",
    " \n",
    "randomCV = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20,cv=10,random_state=7,scoring='roc_auc')\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best = randomCV.best_params_\n",
    "print(best)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "cl = GradientBoostingClassifier(n_estimators=best[\"n_estimators\"],max_depth=best[\"max_depth\"],max_features=best[\"max_features\"],random_state=7)\n",
    "cl_roc = cross_val_score(cl, x_test, y_test, cv=10,scoring=\"roc_auc\")\n",
    "cl_pred = cross_val_predict(cl, x_test, y_test, cv=10)\n",
    "\n",
    "print(\"auc after 10-fold cv: \"+str(cl_roc.mean())+\", SD: \"+str(cl_roc.std()))\n",
    "\n",
    "mat_train = confusion_matrix(y_test,cl_pred,labels=[1,0])\n",
    "cl_cm = pd.DataFrame(mat_train, index = [i for i in [\"Truth(given)\",\"Truth(not given)\"]],\n",
    "                  columns = [i for i in [\"Predict(given)\",\"Predict(not given)\"]])\n",
    "cl_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at the above performance, all the 3 models give good AUC. Lets see the auc on the kaggle test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 85.45% (massive improvement with logistic regression, auc went up to 85.45% from 59% in previous part)\n",
    "\n",
    "final_model = LogisticRegression(penalty = \"l1\",C=45,class_weight=\"balanced\",random_state=7,solver=\"liblinear\")\n",
    "final_model.fit(x,y)\n",
    "final_predictions = final_model.predict_proba(f_test)[:, 1]\n",
    "\n",
    "submit = pd.DataFrame(columns=[\"Id\",\"Action\"])\n",
    "submit[\"Action\"] = final_predictions\n",
    "submit[\"Id\"] = test[\"id\"]\n",
    "#submit.to_csv('PT2-lr.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 77.6% (AUC decresed from 86.5% in part1)\n",
    "\n",
    "final_model = RandomForestClassifier(n_estimators=45,max_depth=11,max_features=5,random_state=7)\n",
    "final_model.fit(x,y)\n",
    "final_predictions = final_model.predict_proba(f_test)[:, 1]\n",
    "\n",
    "submit = pd.DataFrame(columns=[\"Id\",\"Action\"])\n",
    "submit[\"Action\"] = final_predictions\n",
    "submit[\"Id\"] = test[\"id\"]\n",
    "#submit.to_csv('PT2-rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 83.46% (almost same as part1)\n",
    "\n",
    "final_model = GradientBoostingClassifier(n_estimators=125,max_depth=5,max_features=\"sqrt\",random_state=7)\n",
    "final_model.fit(x,y)\n",
    "final_predictions = final_model.predict_proba(f_test)[:, 1]\n",
    "\n",
    "submit = pd.DataFrame(columns=[\"Id\",\"Action\"])\n",
    "submit[\"Action\"] = final_predictions\n",
    "submit[\"Id\"] = test[\"id\"]\n",
    "#submit.to_csv('PT2-gb.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Surprisingly, the kaggle AUC score was expected to be much better since the training performance was remarkably better than part 1. Logistic regression model that completely bombed in part 1 showed a massive improvement in performance with this kind of encoding while at the same time randomforest went down to 77.7% from 85% in part 1. Gradient boosting gave a consistent performance. Also, this methodology is prone to overfitting. The main reason for this is that here we have a strong assumption that the distribution of the categorical variables is same in both test and train test. Clearly, this is not the case. We have seen above that how there are a lot of labels in the test set that are not present in train set (we replaced those labels with global target mean). Other than this, the distribution of the labels that are present in both sets still have somewhat different distribution. It might happen that a label occurs a lot of times in train set but not many times in the test set or there may be a case that a label has higher target 1 probability but a lower probabilty of being target=1 in the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.columns[:10]]\n",
    "test = test[test.columns[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3\n",
    "**kfold mean target encoding. In an attempt to combat the overfitting in the above methodology we will use k-fold target encoding in this part.**<br><br>\n",
    "https://medium.com/@pouryaayria/k-fold-target-encoding-dfe9a594874b#:~:text=In%20the%20mean%2Dtarget%20encoding,the%20target%20corresponding%20to%20them.&text=However%2C%20this%20approach%20might%20have,test%20dataset%20are%20considerably%20different.<br><br>\n",
    "https://necromuralist.github.io/kaggle-competitions/posts/mean-encoding/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train[train.columns[1:]]\n",
    "y=train[\"action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "tt = pd.DataFrame()\n",
    "\n",
    "for tr_idx, val_idx in folds.split(x,y):\n",
    "    \n",
    "    train_fold = train.iloc[tr_idx]\n",
    "    val_fold = train.iloc[val_idx]\n",
    "    \n",
    "    for cols in train.columns[1:]:\n",
    "        mappings = train_fold.groupby(by=cols).mean()['action']\n",
    "        val_fold[cols+\"--new\"] = val_fold[cols].map(mappings)\n",
    "        val_fold[cols+\"--new\"][val_fold[cols+\"--new\"].isnull()] = train_fold[\"action\"].mean()\n",
    "    \n",
    "    #display(val_fold)\n",
    "    tt = tt.append(val_fold) #merging all validation sets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_mean_enc(col):\n",
    "    mapp = tt.groupby(by=col).mean()[col+\"--new\"]\n",
    "    train[col+\"--new\"] = train[col].map(mapp)\n",
    "    test[col+\"--new\"] = test[col].map(mapp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in train.columns[1:]:\n",
    "    kfold_mean_enc(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Again replace all the newly encountered values in test set by global target mean of the training set. Since the newly encountered values in test set will not be mapped therefore they will be replaced by nan. We will replace all the nan values in the test set by global target mean.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test.columns[10:]:\n",
    "    test[col][test[col].isnull()] = train[\"action\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train[train.columns[10:]]\n",
    "y = train[\"action\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100, stratify=y)\n",
    "\n",
    "f_test = test[test.columns[10:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 45, 'class_weight': 'balanced'}\n",
      "\n",
      "auc after 10-fold cv: 0.9590192393464465, SD: 0.010572248692860282\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict(given)</th>\n",
       "      <th>Predict(not given)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Truth(given)</td>\n",
       "      <td>5619</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Truth(not given)</td>\n",
       "      <td>56</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predict(given)  Predict(not given)\n",
       "Truth(given)                5619                 556\n",
       "Truth(not given)              56                 323"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(penalty = \"l1\",random_state=7,solver=\"liblinear\")\n",
    "\n",
    "param_dist = {\"C\": sp_randint(1, 1000),\n",
    "              \"class_weight\": [None,\"balanced\"]}\n",
    " \n",
    "randomCV = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20,cv=10,random_state=7,scoring='roc_auc')\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best = randomCV.best_params_\n",
    "print(best)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "cl = LogisticRegression(penalty = \"l1\",C=best[\"C\"],class_weight=best[\"class_weight\"],random_state=7,solver=\"liblinear\")\n",
    "cl_roc = cross_val_score(cl, x_test, y_test, cv=10,scoring=\"roc_auc\")\n",
    "cl_pred = cross_val_predict(cl, x_test, y_test, cv=10)\n",
    "\n",
    "print(\"auc after 10-fold cv: \"+str(cl_roc.mean())+\", SD: \"+str(cl_roc.std()))\n",
    "\n",
    "mat_train = confusion_matrix(y_test,cl_pred,labels=[1,0])\n",
    "cl_cm = pd.DataFrame(mat_train, index = [i for i in [\"Truth(given)\",\"Truth(not given)\"]],\n",
    "                  columns = [i for i in [\"Predict(given)\",\"Predict(not given)\"]])\n",
    "cl_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**randomforest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 45, 'max_features': 5, 'max_depth': 11, 'class_weight': None}\n",
      "\n",
      "auc after 10-fold cv: 0.9716647650641195, SD: 0.007982734046739\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict(given)</th>\n",
       "      <th>Predict(not given)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Truth(given)</td>\n",
       "      <td>6090</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Truth(not given)</td>\n",
       "      <td>170</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predict(given)  Predict(not given)\n",
       "Truth(given)                6090                  85\n",
       "Truth(not given)             170                 209"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=7)\n",
    "\n",
    "param_dist = {\"max_features\": list(np.arange(1,10))+[None,\"sqrt\"],\n",
    "              \"max_depth\":list(np.arange(3,30))+[None],\n",
    "              \"class_weight\":[None,\"balanced\"],\n",
    "              \"n_estimators\": np.arange(10,150,5)}\n",
    " \n",
    "randomCV = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20,cv=10,random_state=7,scoring='roc_auc')\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best = randomCV.best_params_\n",
    "print(best)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "cl = RandomForestClassifier(n_estimators=best[\"n_estimators\"],max_depth=best[\"max_depth\"],max_features=best[\"max_features\"],class_weight=best[\"class_weight\"],random_state=7)\n",
    "\n",
    "cl_roc = cross_val_score(cl, x_test, y_test, cv=10,scoring=\"roc_auc\")\n",
    "cl_pred = cross_val_predict(cl, x_test, y_test, cv=10)\n",
    "\n",
    "print(\"auc after 10-fold cv: \"+str(cl_roc.mean())+\", SD: \"+str(cl_roc.std()))\n",
    "\n",
    "mat_train = confusion_matrix(y_test,cl_pred,labels=[1,0])\n",
    "cl_cm = pd.DataFrame(mat_train, index = [i for i in [\"Truth(given)\",\"Truth(not given)\"]],\n",
    "                  columns = [i for i in [\"Predict(given)\",\"Predict(not given)\"]])\n",
    "cl_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gradient boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 125, 'max_features': 'sqrt', 'max_depth': 5}\n",
      "\n",
      "auc after 10-fold cv: 0.9730005021709509, SD: 0.006517650044158913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict(given)</th>\n",
       "      <th>Predict(not given)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Truth(given)</td>\n",
       "      <td>6083</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Truth(not given)</td>\n",
       "      <td>174</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predict(given)  Predict(not given)\n",
       "Truth(given)                6083                  92\n",
       "Truth(not given)             174                 205"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(random_state=7)\n",
    "\n",
    "param_dist = {\"max_features\": list(np.arange(1,10))+[None,\"sqrt\"],\n",
    "              \"max_depth\":list(np.arange(3,30))+[None],\n",
    "              \"n_estimators\": np.arange(10,150,5)}\n",
    " \n",
    "randomCV = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20,cv=10,random_state=7,scoring='roc_auc')\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best = randomCV.best_params_\n",
    "print(best)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "cl = GradientBoostingClassifier(n_estimators=best[\"n_estimators\"],max_depth=best[\"max_depth\"],max_features=best[\"max_features\"],random_state=7)\n",
    "cl_roc = cross_val_score(cl, x_test, y_test, cv=10,scoring=\"roc_auc\")\n",
    "cl_pred = cross_val_predict(cl, x_test, y_test, cv=10)\n",
    "\n",
    "print(\"auc after 10-fold cv: \"+str(cl_roc.mean())+\", SD: \"+str(cl_roc.std()))\n",
    "\n",
    "mat_train = confusion_matrix(y_test,cl_pred,labels=[1,0])\n",
    "cl_cm = pd.DataFrame(mat_train, index = [i for i in [\"Truth(given)\",\"Truth(not given)\"]],\n",
    "                  columns = [i for i in [\"Predict(given)\",\"Predict(not given)\"]])\n",
    "cl_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lets evaluate the model on the final kaggle test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 86.1%\n",
    "\n",
    "final_model = LogisticRegression(penalty = \"l1\",C=45,class_weight=\"balanced\",random_state=7,solver=\"liblinear\")\n",
    "final_model.fit(x,y)\n",
    "final_predictions = final_model.predict_proba(f_test)[:, 1]\n",
    "\n",
    "submit = pd.DataFrame(columns=[\"Id\",\"Action\"])\n",
    "submit[\"Action\"] = final_predictions\n",
    "submit[\"Id\"] = test[\"id\"]\n",
    "# submit.to_csv('PT3-lr.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 77.2% (almost same as part2)\n",
    "\n",
    "final_model = RandomForestClassifier(n_estimators=45,max_depth=11,max_features=5,random_state=7)\n",
    "final_model.fit(x,y)\n",
    "final_predictions = final_model.predict_proba(f_test)[:, 1]\n",
    "\n",
    "submit = pd.DataFrame(columns=[\"Id\",\"Action\"])\n",
    "submit[\"Action\"] = final_predictions\n",
    "submit[\"Id\"] = test[\"id\"]\n",
    "# submit.to_csv('PT3-rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 83.2% (almost same as part2)\n",
    "\n",
    "final_model = GradientBoostingClassifier(n_estimators=125,max_depth=5,max_features=\"sqrt\",random_state=7)\n",
    "final_model.fit(x,y)\n",
    "final_predictions = final_model.predict_proba(f_test)[:, 1]\n",
    "\n",
    "submit = pd.DataFrame(columns=[\"Id\",\"Action\"])\n",
    "submit[\"Action\"] = final_predictions\n",
    "submit[\"Id\"] = test[\"id\"]\n",
    "# submit.to_csv('PT3-gb.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we get almost similar results. The distribution in test set is very different from train set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.columns[:10]]\n",
    "test = test[test.columns[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 4\n",
    "**weight of evidence. WOE encodes each feature using the following formula:**<br><br>Lets suppose we have a categorical feature and we are encoding say label 5 (l5) of that feature<br>  \n",
    "vi = log((pi / p) / (ni / n))   where<br>\n",
    "pi = number of l5's with target class 1<br> \n",
    "ni = number of l5's with target class 0<br>\n",
    "p = total number of records with class 1<br>\n",
    "n = total number of records with class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "cols = [col for col in train.columns if col != 'action']\n",
    "woe_encoder = ce.WOEEncoder(cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train[cols]\n",
    "y = train[\"action\"]\n",
    "f_test = test[test.columns[1:]]\n",
    "\n",
    "for c in cols:\n",
    "    x[c] = x[c].astype(\"str\")\n",
    "    f_test[c] = f_test[c].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = woe_encoder.fit_transform(x, y)\n",
    "f_test = woe_encoder.transform(f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 580, 'class_weight': 'balanced'}\n",
      "\n",
      "auc after 10-fold cv: 0.9202257815971088, SD: 0.018717648855262038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict(given)</th>\n",
       "      <th>Predict(not given)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Truth(given)</th>\n",
       "      <td>5258</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Truth(not given)</th>\n",
       "      <td>61</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predict(given)  Predict(not given)\n",
       "Truth(given)                5258                 917\n",
       "Truth(not given)              61                 318"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(penalty = \"l1\",random_state=7,solver=\"liblinear\")\n",
    "\n",
    "param_dist = {\"C\": sp_randint(1, 1000),\n",
    "              \"class_weight\": [None,\"balanced\"]}\n",
    " \n",
    "randomCV = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20,cv=10,random_state=7,scoring='roc_auc')\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best = randomCV.best_params_\n",
    "print(best)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "cl = LogisticRegression(penalty = \"l1\",C=best[\"C\"],class_weight=best[\"class_weight\"],random_state=7,solver=\"liblinear\")\n",
    "cl_roc = cross_val_score(cl, x_test, y_test, cv=10,scoring=\"roc_auc\")\n",
    "cl_pred = cross_val_predict(cl, x_test, y_test, cv=10)\n",
    "\n",
    "print(\"auc after 10-fold cv: \"+str(cl_roc.mean())+\", SD: \"+str(cl_roc.std()))\n",
    "\n",
    "mat_train = confusion_matrix(y_test,cl_pred,labels=[1,0])\n",
    "cl_cm = pd.DataFrame(mat_train, index = [i for i in [\"Truth(given)\",\"Truth(not given)\"]],\n",
    "                  columns = [i for i in [\"Predict(given)\",\"Predict(not given)\"]])\n",
    "cl_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 45, 'max_features': 5, 'max_depth': 11, 'class_weight': None}\n",
      "\n",
      "auc after 10-fold cv: 0.9258807537774327, SD: 0.019822241922205268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict(given)</th>\n",
       "      <th>Predict(not given)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Truth(given)</th>\n",
       "      <td>6092</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Truth(not given)</th>\n",
       "      <td>208</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predict(given)  Predict(not given)\n",
       "Truth(given)                6092                  83\n",
       "Truth(not given)             208                 171"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=7)\n",
    "\n",
    "param_dist = {\"max_features\": list(np.arange(1,10))+[None,\"sqrt\"],\n",
    "              \"max_depth\":list(np.arange(3,30))+[None],\n",
    "              \"class_weight\":[None,\"balanced\"],\n",
    "              \"n_estimators\": np.arange(10,150,5)}\n",
    " \n",
    "randomCV = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20,cv=10,random_state=7,scoring='roc_auc')\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best = randomCV.best_params_\n",
    "print(best)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "cl = RandomForestClassifier(n_estimators=best[\"n_estimators\"],max_depth=best[\"max_depth\"],max_features=best[\"max_features\"],class_weight=best[\"class_weight\"],random_state=7)\n",
    "\n",
    "cl_roc = cross_val_score(cl, x_test, y_test, cv=10,scoring=\"roc_auc\")\n",
    "cl_pred = cross_val_predict(cl, x_test, y_test, cv=10)\n",
    "\n",
    "print(\"auc after 10-fold cv: \"+str(cl_roc.mean())+\", SD: \"+str(cl_roc.std()))\n",
    "\n",
    "mat_train = confusion_matrix(y_test,cl_pred,labels=[1,0])\n",
    "cl_cm = pd.DataFrame(mat_train, index = [i for i in [\"Truth(given)\",\"Truth(not given)\"]],\n",
    "                  columns = [i for i in [\"Predict(given)\",\"Predict(not given)\"]])\n",
    "cl_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gradient boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 125, 'max_features': 'sqrt', 'max_depth': 5}\n",
      "\n",
      "auc after 10-fold cv: 0.9309077636290798, SD: 0.018294911886672552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict(given)</th>\n",
       "      <th>Predict(not given)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Truth(given)</th>\n",
       "      <td>6081</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Truth(not given)</th>\n",
       "      <td>205</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predict(given)  Predict(not given)\n",
       "Truth(given)                6081                  94\n",
       "Truth(not given)             205                 174"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(random_state=7)\n",
    "\n",
    "param_dist = {\"max_features\": list(np.arange(1,10))+[None,\"sqrt\"],\n",
    "              \"max_depth\":list(np.arange(3,30))+[None],\n",
    "              \"n_estimators\": np.arange(10,150,5)}\n",
    " \n",
    "randomCV = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20,cv=10,random_state=7,scoring='roc_auc')\n",
    "randomCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "best = randomCV.best_params_\n",
    "print(best)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "cl = GradientBoostingClassifier(n_estimators=best[\"n_estimators\"],max_depth=best[\"max_depth\"],max_features=best[\"max_features\"],random_state=7)\n",
    "cl_roc = cross_val_score(cl, x_test, y_test, cv=10,scoring=\"roc_auc\")\n",
    "cl_pred = cross_val_predict(cl, x_test, y_test, cv=10)\n",
    "\n",
    "print(\"auc after 10-fold cv: \"+str(cl_roc.mean())+\", SD: \"+str(cl_roc.std()))\n",
    "\n",
    "mat_train = confusion_matrix(y_test,cl_pred,labels=[1,0])\n",
    "cl_cm = pd.DataFrame(mat_train, index = [i for i in [\"Truth(given)\",\"Truth(not given)\"]],\n",
    "                  columns = [i for i in [\"Predict(given)\",\"Predict(not given)\"]])\n",
    "cl_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lets evaluate the model on the final kaggle test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 83.2%\n",
    "\n",
    "final_model = LogisticRegression(penalty = \"l1\",C=580,class_weight=\"balanced\",random_state=7,solver=\"liblinear\")\n",
    "final_model.fit(x,y)\n",
    "final_predictions = final_model.predict_proba(f_test)[:, 1]\n",
    "\n",
    "submit = pd.DataFrame(columns=[\"Id\",\"Action\"])\n",
    "submit[\"Action\"] = final_predictions\n",
    "submit[\"Id\"] = test[\"id\"]\n",
    "#submit.to_csv('PT4-lr.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 86%\n",
    "\n",
    "final_model = RandomForestClassifier(n_estimators=45,max_depth=11,max_features=5,random_state=7)\n",
    "final_model.fit(x,y)\n",
    "final_predictions = final_model.predict_proba(f_test)[:, 1]\n",
    "\n",
    "submit = pd.DataFrame(columns=[\"Id\",\"Action\"])\n",
    "submit[\"Action\"] = final_predictions\n",
    "submit[\"Id\"] = test[\"id\"]\n",
    "#submit.to_csv('PT4-rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 86.65%\n",
    "\n",
    "final_model = GradientBoostingClassifier(n_estimators=125,max_depth=5,max_features=\"sqrt\",random_state=7)\n",
    "final_model.fit(x,y)\n",
    "final_predictions = final_model.predict_proba(f_test)[:, 1]\n",
    "\n",
    "submit = pd.DataFrame(columns=[\"Id\",\"Action\"])\n",
    "submit[\"Action\"] = final_predictions\n",
    "submit[\"Id\"] = test[\"id\"]\n",
    "#submit.to_csv('PT4-gb.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight of evidence gave the most consistent results followed by k-fold target encoding. In k-fold target encoding randomforest did not perform well but with WOE all the models gave good performance.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
